# 06.内存管理

### 目录

- [前言](#前言)
- [什么是内存](#什么是内存)
- [虚拟内存](#虚拟内存)
- [操作系统是如何管理虚拟地址与物理内存地址之间关系](#操作系统是如何管理虚拟地址与物理内存地址之间关系)
  - [内存分段](#内存分段)
  - [内存分页](#内存分页)
  - [段页式内存管理](#段页式内存管理)
- [总结](#总结)
- [参考链接](#参考链接)



</br></br>

## 前言

![内容大纲](https://uploadfiles.nowcoder.com/files/20210622/7841133_1624346396131/0.png)



</br></br>

## 什么是内存

我们想去摆地摊（准备运行程序进程）需要经过那几 个步骤：

首先要去城管申请摊位（申请内存），城管（操作系统）根据现在剩余的地毯空间与你地毯的规模划分一块相应大小的摊位（内存）给你，接着你就可以愉快的摆摊（运行程序进程）赚钱啦。

城管也会时不时的来检查（整理内存空间碎片），摊位是否规整，有没有阻碍正常的人行道。

简而言之，电脑上的程序（进程）运行是需要使用到对应大小的物理内存。



</br></br>

## 虚拟内存

实际上运行的进程并不是直接使用物理内存地址，而是把进程使用的内存地址与实际的物理内存地址做隔离，即操作系统会为每个进程分配独立的一套「**虚拟地址**」。

每个进程使用自己的地址，互不干涉，至于虚拟地址怎么映射到物理地址，对进程来说是透明的，操作系统已经把这些安排的明明白白了。

操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来，如下图所示：

![在这里插入图片描述](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0601.png)
由此我们引出了两个概念:

- 进程中使用的内存地址叫**虚拟地址**
- 存在于计算硬件里的空间地址叫**物理地址**

简单来说就是操作系统引入了虚拟地址，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）来转换成物理地址，再通过物理地址访问物理内存



</br></br>

## 操作系统是如何管理虚拟地址与物理内存地址之间关系

主要有三种方式，分别是**分段、分页、段页**，下面我们来看看这三种内存管理方式

</br>

### 内存分段

**程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。**

</br>

#### 在内存分段方式下，虚拟地址和物理地址是如何映射的？

分段管理下的虚拟地址由两部分组成，段号和段内偏移量

![在这里插入图片描述](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0602.png)

1. 通过段号映射段表的项
2. 从项中获取到段基地址
3. 段基地址+段内偏移量=使用的物理内存

通过上述三步可知，使用段号去映射段表的项，使用项中的段基地址与偏移量计算出物理内存地址，但实际上，分段方式会把程序的虚拟地址分为4段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量计算出物理内存地址

![](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0603.png)



如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。

**分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：**

- `第一个就是"内存碎片"的问题。`
- `第二个就是"内存交换的效率低"的问题。`

接下来对这两个问题进行分析

</br>

#### 分段方式是如何产生内存碎片的？

我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：

- `游戏占用了 512MB 内存`
- `浏览器占用了 128MB 内存`
- `音乐占用了 256 MB 内存。`

这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。

如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。

这个时候我们关闭浏览器，剩余物理内存1024MB -（256MB+512MB）= 256MB。但是这剩余的256MB物理内存不是连续的，被分为了两段128MB，导致没有空间再打开一个200MB的程序，如下图所示

![在这里插入图片描述](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0604.png)

这里的内存碎片的问题共有两处地方：

- `外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载；`
- `内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；`

**针对上面两种内存碎片的问题，解决的方式会有所不同。**

**解决外部内存碎片的问题就是"内存交换"。**

> 可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。
>
> 这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。



</br>

#### 分段方式为什么内存交换效率低？

对于多进程的系统来说，用分段的方式，内存碎片是很容易产生的，产生了内存碎片，那不得不重新 `Swap` 内存区域，这个过程会产生性能瓶颈。

因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。

所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。

为了解决内存分段的内存碎片和内存交换效率低的问题，就出现了内存分页。



</br></br>

### 内存分页

分段的好处就是能产生连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。

要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存分页（Paging）。

**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（Page）。在 Linux 下，每一页的大小为 4KB。

虚拟地址与物理地址是通过**页表**来映射，虚拟空间内的虚拟地址一定是连续的，物理地址不一定，但可以通过连续的虚拟地址把多个不连续的物理内存组合使用。

![在这里插入图片描述](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0605.png)

页表实际上存储在 CPU 的**内存管理单元（MMU）**中，于是 CPU 就可以直接通过 MMU，找出要实际要访问的物理内存地址。

而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

</br>

#### 分页方式是如何解决内存碎片与内存交换效率慢的问题呢？

由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而**采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存**。

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出（Swap Out）**。一旦需要的时候，再加载进来，称为**换入（Swap In）**。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。

![](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0606.png)

**更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

</br>

#### 在内存分页方式下，虚拟地址和物理地址是如何映射的？

在分页机制下，每个进程都会分配一个页表，虚拟地址会分为两部分，页号和页内偏移量，页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，页内偏移量+物理内存基地址就组成了物理内存地址，如下图所示

![在这里插入图片描述](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0607.png)

就是下面这几步

1. 页号找到页表中的页项
2. 获取页项的物理页号基地址
3. 偏移量+物理页号基地址计算出物理内存地址

是不是非常的简单，但是这种分页方式使用到操作系统上会不会问题呢？那必然是会有问题的，还记得之前提到的每个进程会分配一个页表嘛？下面来为大家解开这个伏笔

##### 在分页方式下，每个进程分配一个页表会有什么问题？

每个进程分配一个页表会有空间上的缺陷，因为操作系统上可以运行非常多的进程，那不就意味着页表数量非常多！

```
 ``1B(Byte 字节)=8bit，``1KB (Kilobyte 千字节)=1024B，``1MB (Megabyte 兆字节 简称“兆”)=1024KB，``1GB (Gigabyte 吉字节 又称“千兆”)=1024MB
```

以32 位的环境为例，虚拟地址空间范围共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间范围的映射就要有 4MB 的内存来存储页表。

4MB看起来不大，但是数量上来了就很恐怖了，假设 100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。

为了解决空间上的问题，在对分页方式的基础上，进行优化，出现了多级页表方式



</br>

### 多级页表

在前面我们知道了，分页方式在32位环境下，以每页4KB来计算，一共有100万页，「页表项」需要 4 个字节大小来存储，一个页表包含100万个「页表项」，那么每个进程的页表需要占用4MB大小，多级页表要如何解决这种问题呢？

在页表的基础上做一次二级分页，把100万「页表项」分为一级页表「1024个页表项」,「一级页表项」下又关联二级页表「1024个页表项」，这样一级页表的1024个页表项就覆盖到了4GB的空间范围映射，并且二级页表按需加载，这样页表占用的空间就大大降低。

做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？

![在这里插入图片描述](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0608.png)

接着思考，在二级的基础上是不是又可以继续分级呢，能分二级，必然也能分三级、四级，在64位操作系统是做了四级分页，分为了四个目录，分别是

1. `全局页目录项 PGD（Page Global Directory）；`
2. `上层页目录项 PUD（Page Upper Directory）；`
3. `中间页目录项 PMD（Page Middle Directory）；`
4. `页表项 PTE（Page Table Entry）；`

![在这里插入图片描述](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0609.png)



多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。

![](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0610.png)

我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。

![](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0611.png)

在 CPU 芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。

**有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。**

**TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。**



</br>

##### TBL

多级页表虽然解决了空间上的问题，但是我们发现这种方式需要走多道转换才能找到映射的物理内存地址，经过的多道转换造成了时间上的开销。

程序是局部性的，即在一段时间内，整个程序的执行仅限于程序的某一部分。相应的，执行所访问的存储空间也局限于某个内存区域。

操作系统就利用这一特性，把最多使用的几个页表项放到TBL缓存, CPU 在寻址时，会先查 TBL，如果没找到，才会继续查常规的页表，TBL 的命中率其实很高的，因为程序最常访问的页就那么几个。



</br></br>

### 段页式内存管理

内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理

![](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0612.png)



**段页式内存管理实现的方式：**

- `先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；`
- `接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；`

虚拟地址结构由段号、段内页号和页内位移三部分组成

![在这里插入图片描述](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0613.png)

还有一张图

![](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0614.png)

**段页式地址变换中要得到物理地址须经过三次内存访问：**

- `第一次访问段表，得到页表起始地址；`
- `第二次访问页表，得到物理页号；`
- `第三次将物理页号与页内位移组合，得到物理地址。`



</br></br>

## Linux 内存管理

那么，Linux 操作系统采用了哪种方式来管理内存呢？

在回答这个问题前，我们得先看看 Intel 处理器的发展历史。

早期 Intel 的处理器从 80286 开始使用的是段式内存管理。但是很快发现，光有段式内存管理而没有页式内存管理是不够的，这会使它的 X86 系列会失去市场的竞争力。因此，在不久以后的 80386 中就实现了对页式内存管理。也就是说，80386 除了完成并完善从 80286 开始的段式内存管理的同时还实现了页式内存管理。

但是这个 80386 的页式内存管理设计时，没有绕开段式内存管理，而是建立在段式内存管理的基础上，这就意味着，页式内存管理的作用是在由段式内存管理所映射而成的地址上再加上一层地址映射。

由于此时由段式内存管理映射而成的地址不再是 "物理地址" 了，Intel 就称之为 "线性地址"（也称虚拟地址）。于是，段式内存管理先将逻辑地址映射成线性地址，然后再由页式内存管理将线性地址映射成物理地址。

![img](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0615.png)

**这里说明下逻辑地址和线性地址：**

- `程序所使用的地址，通常是没被段式内存管理映射的地址，称为逻辑地址；`
- `通过段式内存管理映射的地址，称为线性地址，也叫虚拟地址；`

逻辑地址是「段式内存管理」转换前的地址，线性地址则是「页式内存管理」转换前的地址。

了解完 Intel 处理器的发展历史后，我们再来说说 Linux 采用了什么方式管理内存？

Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制

这主要是上面 Intel 处理器发展历史导致的，因为 Intel X86 CPU 一律对程序中使用的地址先进行段式映射，然后才能进行页式映射。既然 CPU 的硬件结构是这样，Linux 内核也只好服从 Intel 的选择。

但是事实上，Linux 内核所采取的办法是使段式映射的过程实际上不起什么作用。也就是说，“上有政策，下有对策”，若惹不起就躲着走。

Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。

我们再来瞧一瞧，Linux 的虚拟地址空间是如何分布的？

在 Linux 操作系统中，虚拟地址空间的内部又被分为**内核空间和用户空间**两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：

![img](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0616.png)

通过这里可以看出：

- `32` 位系统的内核空间占用 `1G`，位于最高处，剩下的 `3G` 是用户空间；
- `64` 位系统的内核空间和用户空间都是 `128T`，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。

再来说说，内核空间与用户空间的区别：

- `进程在用户态时，只能访问用户空间内存；`
- `只有进入内核态后，才可以访问内核空间的内存；`

**虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。**

![img](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0617.png)

接下来，进一步了解虚拟空间的划分情况，用户空间和内核空间划分的方式是不同的，内核空间的分布情况就不多说了。

我们看看用户空间分布的情况，以 32 位系统为例，我画了一张图来表示它们的关系：

![img](https://raw.githubusercontent.com/affectalways/Flee-as-a-bird-to-your-mountain/main/img/system_0618.png)

通过这张图你可以看到，用户空间内存，从低到高分别是 7 种不同的内存段：

- `程序文件段，包括二进制可执行代码；`
- `已初始化数据段，包括静态常量；`
- `未初始化数据段，包括未初始化的静态变量；`
- `堆段，包括动态分配的内存，从低地址开始向上增长；`
- `文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关）；`
- `栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；`

在这 7 个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc 或者 mmap，就可以分别在堆和文件映射段动态分配内存。



</br></br>

### 总结

进程并不是直接使用物理内存，而是通过虚拟地址映射使用，所以操作系统会为每个进程分配虚拟空间(一套地址)，使得每个进程使用物理内存互不影响，相互隔离。

启用大量进程造成内存紧张不足的时候，操作系统会通过内存交换技术，把不常使用的内存加载到硬盘（换出），使用时从硬盘加载到内存（换入）

操作系统对内存的管理方式分为三种，分段、分页、段页，分段的好处是物理内存空间是连续的，但是缺点很明显，容易造成内存碎片，并且内存交换效率慢，采用分页能很好的解决分段的缺陷，通过连续的虚拟地址解决了外部内存碎片问题，每次内存交换将最近不使用的内存以页的单位换出换入，保证交换数据大小，提高内存交换效率，但是会有页表空间占用问题，为了解决此问题，在分页的基础上优化成多级分页+TBL方式来减少空间占用与时间消耗，最后一个就是段页，段页是分段与分页的结合。

通过思考，我们发现，多级分页通过树+懒加载+缓存解决了空间占用与时间消耗的问题，虚拟地址很好的做到了让进程与物理内存地址解耦，正因如此，多进程使用物理内存时才不会有冲突，很好的做到了相互独立与隔离。





</br></br>

### 参考链接

- https://www.cnblogs.com/traditional/p/13256328.html